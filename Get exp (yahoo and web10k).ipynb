{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c811111-5b49-4e04-8709-ddaa5f5a1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d9b3f57-f724-4db4-8051-0b6deace0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import lightgbm\n",
    "import pickle\n",
    "from get_exp_new import lime_exp, shap_exp, random_exp, grad_exp\n",
    "from lirme_v2 import LIRME\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8da0807-adeb-4417-9586-3febfeb08f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Get top 20% important feature and retrain :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3b3fd8-a12e-448b-9abe-fecad311c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'web10k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb3dd1c-27ae-40f0-a3a2-dcd35e5346a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = {\n",
    " 'web10k': {\n",
    "     'train': '/home/amir/code/ltr_document_lvl_explainability/data/web10k/Fold1/train.txt',\n",
    "     'valid': '/home/amir/code/ltr_document_lvl_explainability/data/web10k/Fold1/vali.txt',\n",
    "     'test': '/home/amir/code/ltr_document_lvl_explainability/data/web10k/Fold1/test.txt'\n",
    " },\n",
    " 'yahoo': {\n",
    "     'train': '/home/amir/code/ltr_document_lvl_explainability/data/yahoo/original/set1.train.txt',\n",
    "     'valid': '/home/amir/code/ltr_document_lvl_explainability/data/yahoo/original/set1.valid.txt',\n",
    "     'test': '/home/amir/code/ltr_document_lvl_explainability/data/yahoo/original/set1.test.txt',\n",
    " },\n",
    "  'mq2008':\n",
    "    {\n",
    "     'train': '/home/amir/code/ltr_document_lvl_explainability/data/mq2008/original/train.txt',\n",
    "     'valid': '/home/amir/code/ltr_document_lvl_explainability/data/mq2008/original/vali.txt',\n",
    "     'test': '/home/amir/code/ltr_document_lvl_explainability/data/mq2008/original/test.txt',  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2458e21-e17b-45b5-8292-7d886fd99fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, qid_train = load_svmlight_file(data_path[dataset_name]['train'], query_id=True)\n",
    "x_valid, y_valid, qid_valid = load_svmlight_file(data_path[dataset_name]['valid'], query_id=True)\n",
    "x_test, y_test, qid_test = load_svmlight_file(data_path[dataset_name]['test'], query_id=True)\n",
    "\n",
    "def get_agg_count(qids):\n",
    "    count = []\n",
    "    unique_qids = np.unique(qids)\n",
    "    for i in range(len(unique_qids)):\n",
    "        count.append(len(np.argwhere(qids == unique_qids[i]).flatten()))\n",
    "    return count\n",
    "\n",
    "qid__train = get_agg_count(qid_train)\n",
    "qid__valid = get_agg_count(qid_valid)\n",
    "\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "y_valid = y_valid.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b789ef85-a8f2-4e84-afae-77588359d442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723412, 136)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e551daec-852b-4142-b6d0-08bc709e7c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_docs = []\n",
    "q_doc_idx = []\n",
    "\n",
    "for q in np.unique(qid_test): \n",
    "    doc_idx = np.argwhere(qid_test == q).flatten()\n",
    "    len_docs.append(len(doc_idx))\n",
    "\n",
    "for q in np.unique(qid_test):\n",
    "    doc_idx = np.argwhere(qid_test == q).flatten()\n",
    "    if len(doc_idx) <= np.median(len_docs):\n",
    "        q_doc_idx.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f992c546-52b3-4884-99e9-cbcd3985be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_len_docs = []\n",
    "valid_q_doc_idx = []\n",
    "\n",
    "for q in np.unique(qid_valid): \n",
    "    doc_idx = np.argwhere(qid_valid == q).flatten()\n",
    "    valid_len_docs.append(len(doc_idx))\n",
    "\n",
    "for q in np.unique(qid_valid):\n",
    "    doc_idx = np.argwhere(qid_valid == q).flatten()\n",
    "    if len(doc_idx) <= np.median(valid_len_docs):\n",
    "        valid_q_doc_idx.append(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b72122-4b5f-4b90-ba99-dd113d7d12d6",
   "metadata": {},
   "source": [
    "ranker = lightgbm.LGBMRanker(\n",
    "                    objective=\"lambdarank\",\n",
    "                    boosting_type = \"gbdt\",\n",
    "                    #n_estimators = 25,\n",
    "                    importance_type = \"gain\",\n",
    "                    metric= \"ndcg\",\n",
    "                    #num_leaves = 10,\n",
    "                    #learning_rate = 0.05,\n",
    "                    #max_depth = -1,\n",
    "                    label_gain =[i for i in range(max(y_train.max(), y_test.max()) + 1)])\n",
    "                    \n",
    "                    \n",
    "ranker.fit(\n",
    "      X=x_train,\n",
    "      y=y_train,\n",
    "      group=qid__train,\n",
    "      eval_set=[(x_train, y_train),(x_valid, y_valid)],\n",
    "      eval_group=[qid__train, qid__valid],\n",
    "      eval_at=[5, 10])\n",
    "      \n",
    "ranker.booster_.save_model('./models/lmart_{}_v2.txt'.format(dataset_name))\n",
    "pickle.dump(ranker.evals_result_, open( \"./models/lmart_{}_eval_v2.p\".format(dataset_name), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c5fa8bb-db7b-46bd-9866-7f29a44d67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_q_id_test = np.unique(qid_test)\n",
    "data_sample = {}\n",
    "for i in range(30):\n",
    "    doc_idx = np.argwhere(q_doc_idx[i] == qid_test).flatten()\n",
    "    data_sample[unique_q_id_test[i]] = x_test[doc_idx].toarray()\n",
    "\n",
    "pickle.dump(data_sample, open( \"./data/{}_test_sample_v2.p\".format(dataset_name), \"wb\" ) )\n",
    "\n",
    "\n",
    "unique_q_id_valid = np.unique(qid_valid)\n",
    "\n",
    "data_background = {}\n",
    "for i in range(50):\n",
    "    doc_idx = np.argwhere(valid_q_doc_idx[i] == qid_valid).flatten()\n",
    "    data_background[valid_q_doc_idx[i]] = x_valid[doc_idx].toarray()\n",
    "pickle.dump(data_background, open( \"./data/{}_background_v3.p\".format(dataset_name), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaccd45-1c98-4464-b54e-d227863ed7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = lightgbm.Booster(model_file='./models/lmart_{}.txt'.format(dataset_name))\n",
    "ranker.params['objective'] = 'binary'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d668b-540b-4aa0-a1f0-cefc90a16d80",
   "metadata": {},
   "source": [
    "background_dict = pickle.load( open( \"./data/web10k_background.p\", \"rb\" ) )\n",
    "test = pickle.load( open( \"./data/web10k_test_sample.p\", \"rb\" ) )\n",
    "\n",
    "background = []\n",
    "for q in background_dict:\n",
    "    background.extend(background_dict[q])\n",
    "background = np.array(background).reshape(-1, test[13].shape[1])\n",
    "\n",
    "lirme = LIRME(background)\n",
    "e_sample_size = 4000\n",
    "\n",
    "p_exps = {}\n",
    "#exps = {'lime': [],  'shap': [], 'lirme': [], 'exs_v1': [],  'exs_v2': [], 'grad_d': [], 'random_d': []}\n",
    "pointwise_exp = ['lime', 'shap', 'lirme', 'exs_v1', 'exs_v2', 'grad_d', 'random_d']\n",
    "\n",
    "#for key in test.keys():\n",
    "for key in [13]:\n",
    "    p_exps[key] = {}\n",
    "    for e in pointwise_exp:\n",
    "        p_exps[key][e] = []\n",
    "    print(p_exps)\n",
    "    q_docs = test[key]\n",
    "    pred_q_docs = ranker.predict(q_docs)\n",
    "    print(q_docs.shape, pred_q_docs)\n",
    "        \n",
    "    #for i in range(len(q_docs)): \n",
    "    for i in range(2): \n",
    "        instance = q_docs[i]\n",
    "        p_exps[key]['lime'].append(lime_exp(instance, ranker, background, sample_size=e_sample_size))\n",
    "        p_exps[key]['shap'].append(shap_exp(instance, background, ranker, sample_size=e_sample_size))\n",
    "\n",
    "\n",
    "        exp_lirme = lirme.explain(instance, ranker.predict, pred_q_docs, \n",
    "                    sur_type='ridge', label_type='regression', \n",
    "                    instance_idx=i, top_rank=5, sample_size=e_sample_size)\n",
    "        p_exps[key]['lirme'].append(exp_lirme)\n",
    "\n",
    "        gradient_exp = grad_exp(instance, ranker)\n",
    "        p_exps[key]['grad_d'].append(gradient_exp)\n",
    "\n",
    "        exp_exs_v1 = lirme.explain(instance, ranker.predict, pred_q_docs, \n",
    "                    sur_type='svm', label_type='top_k_binary', \n",
    "                    instance_idx=i, top_rank=5, sample_size=e_sample_size)\n",
    "        p_exps[key]['exs_v1'].append(exp_exs_v1)\n",
    "\n",
    "        exp_exs_v2 = lirme.explain(instance, ranker.predict, pred_q_docs, \n",
    "                    sur_type='svm', label_type='score', \n",
    "                    instance_idx=i, top_rank=5, sample_size=e_sample_size)\n",
    "        p_exps[key]['exs_v2'].append(exp_exs_v2)\n",
    "\n",
    "        p_exps[key]['random_d'].append(random_exp(instance.shape[0]))\n",
    "\n",
    "pickle.dump(p_exps, open( \"./web10k_pointwise_exps.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15155577-8f37-4845-85c1-50c3487aa03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointwise_exp = pickle.load( open( \"./exps/{}_pointwise_exps_v1.p\".format(dataset_name), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f8161b3-1a4e-487e-a80e-ad738ae102f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lime', 'shap', 'lirme', 'exs_v1', 'exs_v2', 'grad_d', 'random_d'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_exp[13].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f33d9-2d74-4797-8ca3-a476c8c00fce",
   "metadata": {},
   "source": [
    "from listwise_exp import pmi_exp, rpi_exp, grad_q_exp, greedy_exp, random_q_exp\n",
    "listwise_exp = ['pmi', 'rpi', 'grad', 'rank_lime', 'greedy_score', 'random']\n",
    "\n",
    "from ranklime import RankLIME\n",
    "rlime = RankLIME(background)\n",
    "\n",
    "l_exps = {}\n",
    "\n",
    "for key in [13]:\n",
    "    doc_values = test[key]\n",
    "    l_exps[key] = {}\n",
    "    for e in listwise_exp:\n",
    "        l_exps[key][e] = {}\n",
    "    \n",
    "    l_exps[key]['pmi'] = pmi_exp(doc_values, ranker)\n",
    "    l_exps[key]['rpi'] = rpi_exp(doc_values, ranker)\n",
    "    l_exps[key]['grad'] = grad_q_exp(doc_values, ranker)\n",
    "    l_exps[key]['rank_lime'] = rlime.explain(doc_values, ranker.predict, [])\n",
    "    l_exps[key]['greedy_score'] = greedy_exp(doc_values, ranker.predict)\n",
    "    l_exps[key]['random'] = random_q_exp(doc_values)\n",
    "\n",
    "pickle.dump(l_exps, open( \"./exps/web10k_listwise_exps.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78edca72-d210-435b-acec-26e75986c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "listwise_exp = pickle.load( open( \"./exps/{}_listwise_exps.p\".format(dataset_name), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef19cc7-1524-41e0-a620-4ecfa268a8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pmi', 'rpi', 'grad', 'rank_lime', 'greedy_score', 'random'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise_exp[13].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80129d7d-fcf0-409c-b9d8-d60746bdda51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
